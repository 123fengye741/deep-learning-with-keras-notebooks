{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用Keras函數式API進行深度學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras使得創建深度學習模型變得快速而簡單。\n",
    "\n",
    "序貫(sequential)API允許您為大多數問題逐層堆疊創建模型。雖然說對很多的應用來說, 這樣的一個手法很簡單也解決\n",
    "了很多深度學習網絡結構的構建，但是它也有限制 - 它不允許你創建模型有共享層或有多個輸入或輸出的網絡。\n",
    "\n",
    "Keras中的函數式(functional)API是創建網絡模型的另一種方式，它提供了更多的靈活性，包括創建更複雜的模型。\n",
    "\n",
    "在這個文章中，您將了解如何使用Keras中更靈活的函數式(functional)API來定義深度學習模型。\n",
    "\n",
    "完成這個文章的相關範例, 您將知道：\n",
    "* Sequential和Functional API之間的區別。\n",
    "* 如何使用功能性(functional)API定義簡單的多層感知器(MLP)，卷積神經網絡(CNN)和遞歸神經網絡(RNN)模型。\n",
    "* 如何用共享層和多個輸入輸出來定義更複雜的模型。\n",
    "\n",
    "![network topology](https://www.codeproject.com/KB/AI/1215045/Popular-Neural-Network-Architecture.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-7-6.1.7601-SP1\n",
      "Tensorflow version: 1.4.0\n",
      "Keras version: 2.1.1\n"
     ]
    }
   ],
   "source": [
    "# 這個Jupyter Notebook的環境\n",
    "import platform\n",
    "import tensorflow\n",
    "import keras\n",
    "print(\"Platform: {}\".format(platform.platform()))\n",
    "print(\"Tensorflow version: {}\".format(tensorflow.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Keras 序貫模型 (Sequential Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras提供了一個Sequential模型API。\n",
    "\n",
    "它是創建深度學習模型的一種相對簡單的方法，我們透過創建Kears的Sequential類別實例(instance), 然後創建模型圖層\n",
    "並添加到其中。\n",
    "\n",
    "例如，可以定義多個圖層並將以陣列的方式一次做為參數傳遞給Sequential："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 構建模型\n",
    "model = Sequential([Dense(2, input_shape=(1,)), Dense(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當然我們也可以一層一層也分段添加上去："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 構建模型\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(1,)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential模型API對於在大多數情況下非常有用與方便，但也有一些局限性。\n",
    "例如，網絡拓撲結構可能具有多個不同輸入，產生多個輸出或重複使用共享圖層的複雜模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras 函數式(functional)API構建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras函數式(functional)API為構建網絡模型提供了更為靈活的方式。\n",
    "\n",
    "它允許您定義多個輸入或輸出模型以及共享圖層的模型。除此之外，它允許您定義動態(ad-hoc)的非週期性(acyclic)網絡圖。\n",
    "\n",
    "模型是通過創建層的實例(layer instances)並將它們直接相互連接成對來定義的，然後定義一個模型(model)來指定那些層是要作為\n",
    "這個模型的輸入和輸出。\n",
    "\n",
    "讓我們依次看看Keras功能(functional)API的三個獨特特性："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 定義輸入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "與Sequential模型不同，您必須創建獨立的Input層物件的instance並定義輸入數據張量的維度形狀(tensor shape)。\n",
    "\n",
    "輸入層採用一個張量形狀參數(tensor shape)，它是一個tuple，用於宣吿輸入張量的維度。\n",
    "\n",
    "例如: 我們要把MNIST的每張圖像(28x28)打平成一個一維(784)的張量做為一個多層感知器(MLP)的Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "mnist_input = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 連接不同的網絡層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型中的神經層是成對連接的,就像是一個樂高積木一樣有一面是凸一面是凹, 一個神經層的輸出會接到另一個神經層的輸入。\n",
    "\n",
    "這是通過在定義每個新神經層時指定輸入的來源來完成的。使用括號表示法，以便在創建圖層之後，指定作為輸入的神經層。\n",
    "\n",
    "我們用一個簡短的例子來說明這一點。我們可以像上面那樣創建輸入層，然後創建一個隱藏層作為密集層，它接收來自輸入層的輸入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "\n",
    "mnist_input = Input(shape=(784,))\n",
    "hidden = Dense(512)(mnist_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正是這種逐層連接的方式賦予功能性(functional)API靈活性。您可以看到開始一些動態的神經網絡是多麼容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 創建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在創建所有模型圖層並將它們連接在一起之後，您必須定義一個模型(Model)物件的instance。\n",
    "\n",
    "與Sequential API一樣，這個模型是您可以用於總結(summarize)，擬合(fit)，評估(evaluate)和預測(predict)。\n",
    "\n",
    "Keras提供了一個Model類別，您可以使用它從創建的圖層創建模型的instance。它會要求您只指定整個模型的第一個輸入層和最後一個的輸出層。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "mnist_input = Input(shape=(784,))\n",
    "hidden = Dense(512)(mnist_input)\n",
    "\n",
    "model = Model(inputs=mnist_input, outputs=hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們已經知道了Keras函數式API的所有關鍵部分，讓我們通過定義一系列不同的模型來開展工作。\n",
    "\n",
    "每個範例都是可以執行的，並打印網絡結構及產生網絡圖表。我建議你為自己的模型做這個事情，以明確你所定義的是什麼樣的網絡結構。\n",
    "\n",
    "我希望這些範例能夠在將來使用函數式API定義自己的模型時為您提供模板。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.標準網絡模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在開始使用函數式API時，最好先看一些標準的神經網絡模型是如何定義的。\n",
    "\n",
    "在本節中，我們將著眼於定義一個簡單的多層感知器(MLP)，卷積神經網絡(CNN)和遞歸神經網絡(RNN)。\n",
    "\n",
    "這些範例將為以後了解更複雜的網絡構建提供基礎。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 多層感知器(Multilayer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們來定義了一個多類別分類(multi-class classification)的多層感知器(MLP)模型。\n",
    "\n",
    "該模型有784個輸入，3個隱藏層，512,216和128個隱藏神經元，輸出層有10個輸出。\n",
    "\n",
    "在每個隱藏層中使用`relu`激活函數，並且在輸出層中使用`softmax`激活函數進行多類別分類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 128)               27776     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 541,794\n",
      "Trainable params: 541,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 多層感知器(MLP)模型\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.utils import plot_model\n",
    "\n",
    "mnist_input = Input(shape=(784,), name='input')\n",
    "hidden1 = Dense(512, activation='relu', name='hidden1')(mnist_input)\n",
    "hidden2 = Dense(216, activation='relu', name='hidden2')(hidden1)\n",
    "hidden3 = Dense(128, activation='relu', name='hidden3')(hidden2)\n",
    "output = Dense(10, activation='softmax', name='output')(hidden3)\n",
    "\n",
    "model = Model(inputs=mnist_input, outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# 產生網絡拓撲圖\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multilayer_perceptron_graph](multilayer_perceptron_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 卷積神經網絡(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將定義一個用於圖像分類的卷積神經網絡(convolutional neural network)。\n",
    "\n",
    "該模型接收灰階的28×28圖像作為輸入，然後有一個作為特徵提取器的兩個卷積和池化層的序列，\n",
    "然後是一個完全連接層來解釋特徵，並且具有用於10類預測的`softmax`激活的輸出層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 25, 25, 128)       2176      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 9, 9, 64)          131136    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 4, 4, 64)          4160      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4, 4, 10)          650       \n",
      "=================================================================\n",
      "Total params: 138,122\n",
      "Trainable params: 138,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 卷積神經網絡(CNN)\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "mnist_input = Input(shape=(28, 28, 1), name='input')\n",
    "\n",
    "conv1 = Conv2D(128, kernel_size=4, activation='relu', name='conv1')(mnist_input)\n",
    "pool1 = MaxPool2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, kernel_size=4, activation='relu', name='conv2')(pool1)\n",
    "pool2 = MaxPool2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "hidden1 = Dense(64, activation='relu', name='hidden1')(pool2)\n",
    "output = Dense(10, activation='softmax', name='output')(hidden1)\n",
    "model = Model(inputs=mnist_input, outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# 產生網絡拓撲圖\n",
    "plot_model(model, to_file='convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![convolutional_neural_network](convolutional_neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 遞歸神經網絡(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將定義一個長期短期記憶(LSTM)遞歸神經網絡用於圖像分類。\n",
    "\n",
    "該模型預期一個特徵的784個時間步驟作為輸入。該模型具有單個LSTM隱藏層以從序列中提取特徵，\n",
    "接著是完全連接的層來解釋LSTM輸出，接著是用於進行10類別預測的輸出層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 84,362\n",
      "Trainable params: 84,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 遞歸神經網絡(RNN)\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import plot_model\n",
    "\n",
    "mnist_input = Input(shape=(784, 1), name='input') # 把每一個像素想成是一序列有前後關係的time_steps\n",
    "lstm1 = LSTM(128, name='lstm1')(mnist_input)\n",
    "hidden1 = Dense(128, activation='relu', name='hidden1')(lstm1)\n",
    "output = Dense(10, activation='softmax', name='output')(hidden1)\n",
    "model = Model(inputs=mnist_input, outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# 產生網絡拓撲圖\n",
    "plot_model(model, to_file='recurrent_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![recurrent_neural_network](recurrent_neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.共享層模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多個神經層可以共享一個神經層的輸出來當成輸入。\n",
    "\n",
    "例如，一個輸入可能可以有多個不同的特徵提取層，或者多個神經層用於解釋特徵提取層的輸出。\n",
    "\n",
    "我們來看這兩個例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 共享輸入層 (Shared Input Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們定義具有不同大小的內核的多個卷積層來解釋圖像輸入。\n",
    "\n",
    "該模型使用28×28像素的灰階圖像。有兩個CNN特徵提取子模型共享這個輸入;第一個具有4的內核大小和第二個8的內核大小。\n",
    "這些特徵提取子模型的輸出被平坦化(flatten)為向量(vector)，並且被串連成一個長向量, 然後被傳遞到完全連接的層以\n",
    "用於在最終輸出層之前進行10類別預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 25, 25, 32)   544         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 21, 21, 16)   1040        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 12, 12, 32)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 10, 10, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4608)         0           pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1600)         0           pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6208)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 64)           397376      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           650         hidden1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 399,610\n",
      "Trainable params: 399,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 共享輸入層 \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# 輸入層\n",
    "mnist_input = Input(shape=(28, 28, 1), name='input')\n",
    "\n",
    "# 第一個特徵提取層\n",
    "conv1 = Conv2D(32, kernel_size=4, activation='relu', name='conv1')(mnist_input) # <-- 看這裡\n",
    "pool1 = MaxPool2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "flat1 = Flatten()(pool1)\n",
    "\n",
    "# 第二個特徵提取層\n",
    "conv2 = Conv2D(16, kernel_size=8, activation='relu', name='conv2')(mnist_input) # <-- 看這裡\n",
    "pool2 = MaxPool2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "flat2 = Flatten()(pool2)\n",
    "\n",
    "# 把兩個特徵提取層的結果併起來\n",
    "merge = concatenate([flat1, flat2])\n",
    "\n",
    "# 進行全連結層\n",
    "hidden1 = Dense(64, activation='relu', name='hidden1')(merge)\n",
    "\n",
    "# 輸出層\n",
    "output = Dense(10, activation='softmax', name='output')(hidden1)\n",
    "\n",
    "# 以Model來組合整個網絡\n",
    "model = Model(inputs=mnist_input, outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# plot graph\n",
    "plot_model(model, to_file='shared_input_layer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shared_input_layer](shared_input_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2 共享特徵提取層 (Shared Feature Extraction Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "我們將使用兩個並行子模型來解釋用於序列分類的LSTM特徵提取器的輸出。\n",
    "\n",
    "該模型的輸入是1個特徵的784個時間步長。具有10個存儲單元的LSTM層解釋這個序列。第一種解釋模型是淺層單連通層，\n",
    "第二層是深層3層模型。兩個解釋模型的輸出連接成一個長向量，傳遞給用於進行10類別分類預測的輸出層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 784, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 128)          66560       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "interp21 (Dense)                (None, 64)           8256        lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "interp22 (Dense)                (None, 32)           2080        interp21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "interp1 (Dense)                 (None, 10)           1290        lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "interp23 (Dense)                (None, 16)           528         interp22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 26)           0           interp1[0][0]                    \n",
      "                                                                 interp23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           270         merge[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 78,984\n",
      "Trainable params: 78,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "# 輸入層\n",
    "mnist_input = Input(shape=(784, 1), name='input') # 把每一個像素想成是一序列有前後關係的time_steps\n",
    "\n",
    "# 特徵提取層\n",
    "extract1 = LSTM(128, name='lstm1')(mnist_input)\n",
    "\n",
    "# 第一個解釋層\n",
    "interp1 = Dense(10, activation='relu', name='interp1')(extract1) # <-- 看這裡\n",
    "\n",
    "# 第二個解釋層\n",
    "interp21 = Dense(64, activation='relu', name='interp21')(extract1) # <-- 看這裡\n",
    "interp22 = Dense(32, activation='relu', name='interp22')(interp21)\n",
    "interp23 = Dense(16, activation='relu', name='interp23')(interp22)\n",
    "\n",
    "# 把兩個特徵提取層的結果併起來\n",
    "merge = concatenate([interp1, interp23], name='merge')\n",
    "\n",
    "# 輸出層\n",
    "output = Dense(10, activation='softmax', name='output')(merge)\n",
    "\n",
    "# 以Model來組合整個網絡\n",
    "model = Model(inputs=mnist_input, outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# plot graph\n",
    "plot_model(model, to_file='shared_feature_extractor.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shared_feature_extractor](shared_feature_extractor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.多種輸入和輸出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "函數式(functional)API也可用於開發具有多個輸入或多個輸出的模型的更複雜的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 多輸入模型\n",
    "\n",
    "我們將開發一個圖像分類模型，將圖像的兩個版本作為輸入，每個圖像的大小不同。特別是一個灰階的64×64版本和一個32×32的彩色版本。分離的特徵提取CNN模型對每個模型進行操作，然後將兩個模型的結果連接起來進行解釋和最終預測。\n",
    "\n",
    "請注意，在創建Model（）實例(instance)時，我們將兩個輸入圖層定義為一個數組(array)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_gray_bigsize (InputLayer)   (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_rgb_smallsize (InputLayer)  (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv11 (Conv2D)                 (None, 61, 61, 32)   544         img_gray_bigsize[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv21 (Conv2D)                 (None, 29, 29, 32)   1568        img_rgb_smallsize[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool11 (MaxPooling2D)           (None, 30, 30, 32)   0           conv11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool21 (MaxPooling2D)           (None, 14, 14, 32)   0           conv21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv12 (Conv2D)                 (None, 27, 27, 16)   8208        pool11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv22 (Conv2D)                 (None, 11, 11, 16)   8208        pool21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool12 (MaxPooling2D)           (None, 13, 13, 16)   0           conv12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool22 (MaxPooling2D)           (None, 5, 5, 16)     0           conv22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2704)         0           pool12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 400)          0           pool22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3104)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 128)          397440      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 64)           8256        hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           650         hidden2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 424,874\n",
      "Trainable params: 424,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 多輸入模型\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# 第一個輸入層\n",
    "img_gray_bigsize = Input(shape=(64, 64, 1), name='img_gray_bigsize')\n",
    "conv11 = Conv2D(32, kernel_size=4, activation='relu', name='conv11')(img_gray_bigsize)\n",
    "pool11 = MaxPool2D(pool_size=(2, 2), name='pool11')(conv11)\n",
    "conv12 = Conv2D(16, kernel_size=4, activation='relu', name='conv12')(pool11)\n",
    "pool12 = MaxPool2D(pool_size=(2, 2), name='pool12')(conv12)\n",
    "flat1 = Flatten()(pool12)\n",
    "\n",
    "# 第二個輸入層\n",
    "img_rgb_smallsize = Input(shape=(32, 32, 3), name='img_rgb_smallsize')\n",
    "conv21 = Conv2D(32, kernel_size=4, activation='relu', name='conv21')(img_rgb_smallsize)\n",
    "pool21 = MaxPool2D(pool_size=(2, 2), name='pool21')(conv21)\n",
    "conv22 = Conv2D(16, kernel_size=4, activation='relu', name='conv22')(pool21)\n",
    "pool22 = MaxPool2D(pool_size=(2, 2), name='pool22')(conv22)\n",
    "flat2 = Flatten()(pool22)\n",
    "\n",
    "# 把兩個特徵提取層的結果併起來\n",
    "merge = concatenate([flat1, flat2])\n",
    "\n",
    "# 用隱藏的全連結層來解釋特徵\n",
    "hidden1 = Dense(128, activation='relu', name='hidden1')(merge)\n",
    "hidden2 = Dense(64, activation='relu', name='hidden2')(hidden1)\n",
    "\n",
    "# 輸出層\n",
    "output = Dense(10, activation='softmax', name='output')(hidden2)\n",
    "\n",
    "# 以Model來組合整個網絡\n",
    "model = Model(inputs=[img_gray_bigsize, img_rgb_smallsize], outputs=output)\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# plot graph\n",
    "plot_model(model, to_file='multiple_inputs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple_inputs](multiple_inputs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.2 多輸出模型\n",
    "\n",
    "我們將開發一個模型，進行兩種不同類型的預測。給定一個特徵的784個時間步長的輸入序列，該模型將對該序列進行分類並輸出具有相同長度的新序列。\n",
    "\n",
    "LSTM層解釋輸入序列並返回每個時間步的隱藏狀態。第一個輸出模型創建一個堆疊的LSTM，解釋這些特徵，並進行多類別預測。第二個輸出模型使用相同的輸出層對每個輸入時間步進行多類別預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多輸出模型\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# 輸入層\n",
    "mnist_input = Input(shape=(784, 1), name='input') # 把每一個像素想成是一序列有前後關係的time_steps\n",
    "\n",
    "# 特徵擷取層\n",
    "extract = LSTM(64, return_sequences=True, name='extract')(mnist_input)\n",
    "\n",
    "# 分類輸出\n",
    "class11 = LSTM(32, name='class11')(extract)\n",
    "class12 = Dense(32, activation='relu', name='class12')(class11)\n",
    "output1 = Dense(10, activation='softmax', name='output1')(class12)\n",
    "\n",
    "# 序列輸出\n",
    "output2 = TimeDistributed(Dense(10, activation='softmax'), name='output2')(extract)\n",
    "\n",
    "# 以Model來組合整個網絡\n",
    "model = Model(inputs=mnist_input, outputs=[output1, output2])\n",
    "\n",
    "# 打印網絡結構\n",
    "model.summary()\n",
    "\n",
    "# plot graph\n",
    "plot_model(model, to_file='multiple_outputs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple_outputs](multiple_outputs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.最佳實踐\n",
    "以上有一些小技巧可以幫助你充分利用函數式API定義自己的模型。\n",
    "* **一致性的變量名稱命名** 對輸入（可見）和輸出神經層（輸出）使用相同的變量名，甚至可以使用隱藏層（hidden1，hidden2）。這將有助於正確地將許多的神經層連接在一起。\n",
    "* **檢查圖層摘要** 始終打印模型摘要並查看圖層輸出，以確保模型如您所期望的那樣連接在一起。\n",
    "* **查看網絡拓樸圖像** 總是儘可能地創建網絡拓樸圖像，並審查它，以確保一切按照你的意圖連接在一起。\n",
    "* **命名圖層** 您可以為圖層指定名稱,這些名稱可以讓你的模型圖形摘要和網絡拓樸圖像更容易被解讀。例如：Dense（1，name ='hidden1'）。\n",
    "* **獨立子模型** 考慮分離出子模型的發展，並最終將子模型結合在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結 (Conclusion)\n",
    "\n",
    "在這篇文章中有一些個人學習到的一些有趣的重點:\n",
    "    \n",
    "* 使用Keras也可以很靈活地來建構複雜的深度學習網絡\n",
    "* 每一種深度學習網絡拓樸基本上都可以找的到一篇論文\n",
    "* 了解每種深度學習網絡拓樸架構的原理與應用的方向是強化內力的不二法門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考: \n",
    "* [How to Use the Keras Functional API for Deep Learning](https://machinelearningmastery.com/keras-functional-api-deep-learning/)\n",
    "* [Keras官網](http://keras.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
